### Chapt 3 入门

#### 3.2 字符串类型

* ``SET [key] [value]``，设置键值。

* ``GET [key]``，获取指定键的值。

* ``INCR [key]``，存储的字符串必须整数形式，能够进行整型数值运算的。

* 所有 Redis 命令均为原子操作。

* 键名比较好用的实践是 ”对象类型:对象ID:对象属性”.

* 自增 ID，对每一类对象使用名为对象类型（复数形式）:count的键，如 ``users:count`` 来记录。

* 字符串类型键只能存储一个字符串，因此内部的内容需要序列化或二进制化。

* 发布新文章的伪代码：

  ```
  $postID = INCR posts:count
  $serializedPost = serialize($title, $content, $author, $time)
  SET post:$postID:data $serializedPost
  ```

* 读取文章数据的伪代码：

  ```
  $serializedPost = GET post:4:data
  $title, $content, $author, $time = unserialize($serializedPost) 反序列化
  $count = INCR post:4:page.view 递增并获取文章访问量
  ```

* 增加指定整数，``INCRBY [key] [increment]``，同 ``INCR`` 相近但可以指定增加数。

* 减少指定整数，``DECR [key]``、``DECRBY [key] [increment]``。

* 增加指定浮点数，``INCRBYFLOAT [key] [increment]``。

* 向尾部增加值，``APPEND [key] [value]``，向字符串末尾加值（如 ”1“、“hello”），有空格需要加上双引号，加完符号字符串后不再是数值。

* 获取字符串长度，``STRLEN [key]``，键不存在则返回 0。

* 同时获得多个键值，``MGET [key ...]``，如``MGET foo bat``。

* 同时设置多个键值，``MSET key value [key value ...]``，如``MSET aaa 1 bbb 2``。

* 位操作：

  * ``GETBIT key offset``，获得左数第 offset 位的二进制值，索引从 0 开始。
  * ``SETBIT key offset value``，设置左数第 offset 位的二进制值。
  * ``BITCOUNT key [start] [end]``，获得字符串类型键中值是 1 的二进制位个数，索引是键值的字符数。
  * ``BITOP``：
    * ``BITOP operation destkey key [key ...]``；
    * 可以对多个字符串类型键位进行位运算，并将结果存储在 destkey 中；
    * 支持的位运算操作有 AND、OR、XOR、NOT；
  * ``BITPOS``，可以获得指定键的第一位值是 0 或 1 的位置；增加参数可以指定要查询的起始字节（从 0 开始算）和结束字节，如 ``BITPOS foo 1 1 2``。

#### 3.3 散列类型

* 散列类型适合存储对象：使用对象类别和 ID 构成键名，使用字段表示对象的属性，而字段值则存储属性值。

* 散列类型意味着同一个键中可以随意增删改查字段和字段值。

* ``HSET key field value``，用来给键内字段赋值。

* ``HGET key field``，用来过去键内字段的值。

* ``HMSET key field value [field value ...]``，设置键内多个字段的值。

* ``HMGET key field [field ...]``，获取键内多个字段的值。

* ``HSET`` 不区分插入和更新操作，不需要事先判断，插入操作会返回 1，更新操作会返回 0；另外，键不存在也会自动建立。

* 每个键都有明确的数据类型，在通过命令建立时就已经确定。

* ``HGETALL key``，用于获得键内的所有字段和字段值，在语言的 redis 客户端中会封装成编程语言的对象。

* ``HEXISTS key field``，判断某个字段是否存在。

* ``HSETNX key field value``，与 HSET 命令类似，区别在于若字段已存在命令将不执行操作，而且是原子操作，不需要担心竞态条件。

* ``HINCRBY key field increment``，向指定的键字段内增加整数，如果原来不存在也会自动创建并默认为0.

* ``HDEL key field [field ...]``，可以删除一个或多个字段，返回值是被删除的字段个数。

* 要只提取一部分内容，有方法是组合使用多个字符串类型键来存储一篇文章的数据。

* 使用散列结构更好，而且更加节约空间。

* 散列类型也可以用来存储映射关系，比如 ``slug.to.id``，字段用来纪录缩略名，字段值用来记录对应 ID，就可以用 HEXISTS 命令来判断是否存在，用 HGET 命令来获取缩略名对应的 ID 了。

  ```
  $postID = INCR posts:count
  $isSlugAvailable = HSETNX slug.to.id, $slug, $postID // 用原子命令 HSETNX 避免竞态条件
  if $isSlugAvailable is 0:
  	...
  	exit
  HMSET post:$postID, title, $title, content, $content, ...
  ```

* ``HKEYS key``、``HVALS key``，只获取字段名或字段值，前者虽然是 KEYS 却是获得字段名。

* ``HLEN key``，获得字段的数量。

#### 3.4 列表类型

* 列表类型可以存储有序的字符串列表，常用的操作是向列表两端添加元素，或者获得列表的某一个片段。

* 列表类型内部使用双向链表实现。

* 列表能够快速获取首尾两端的内容，也适合用作日志记录，还可以使 redis 作为队列使用。

* 列表类型键最多能容纳2^32-1个元素。

* ``LPUSH key value [value ...]``、``RPUSH key value [value ...]``，向列表左右增加元素，返回值表示增加元素后列表的长度。

* ``LPOP key``、``RPOP key``，从列表两端弹出元素。执行两步操作，第一步是将元素从列表移除，第二步是返回被移除的元素值。

* 依此可以模拟栈和队列的操作。

* ``LLEN key``，获取列表中元素的个数。

* ``LRANGE key start stop``，获得列表中的某一片段，起始索引为 0，且包含两端的元素，支持负索引。

* ``LREM key count value``，删除列表中前 count 个值为 value 的元素，返回删除元素的个数。

  * count > 0，会从左边开始删除 count 个值；
  * count < 0，会从右边开始删除 -count 个值；
  * count = 0，会删除所有 value 的元素。

* 有了文章 ID 列表，可以使用 LRANGE 命令来实现文章的分页显示。

  ```
  $postsPerPage = 10
  $start = ($currentPage - 1) * $postsPerPage
  $end = $currentPage * $postsPerPage - 1
  $postsID = LRANGE posts:list, $start, $end
  # 获得了此页需要显示的文章 ID 列表，通过循环的方式来读取文章
  for each $id in $postsID
  	$post = HGETALL post:$id
  	print 文章标题：$post.title
  ```

* 上述伪代码中，散列类型没有类似字符串类型的 MGET 命令那样可以通过一条命令同时获得多个键的键值版本，因此对每个文章 ID 都要请求一次数据库，也都会产生一次往返时延，之后会介绍使用管道和脚本来优化这个问题。

* 列表类型的重排操作复杂，且访问中间内容的性能较差，是需要在使用中避免的问题。

* ``LINDEX key index``、``LSET key index value``，获得/设置指定索引的元素值。

* ``LTRIM key start end``，保留列表的指定片段，是闭区间。

* ``LINSERT key BEFORE|AFTER pivot value``，从左到右查找到 pivot 再在前或后插入元素 value。

* ``RPOPLPUSH source destination``，从 source 右边弹出一个元素，添加到 destination 的左边，并返回这个元素的值，整个过程是原子的。

* ``RPOPLPUSH`` 命令可以直观地在多个队列中传递数据，而且原子语句不需要考虑竞态。

#### 3.5 集合类型

* 集合类型的键可以存储至多 2^32-1 个字符串。
* 集合类型在 Redis 内部是使用值为空的散列表（hash table）实现的，所以操作复杂度均为 O(1)。
* 多个集合类型键之间还可以进行并集、交集和差集运算。
* ``SADD key member [member ...]``、``SREM key member [member ...]``，增加和删除元素，返回加入的或删除的元素数量。
* ``SMEMBERS key``，返回集合中所有的元素。
* ``SISMEMBER key member``，判断元素是否在集合中，时间复杂度 O(1)，存在即返回 0。
* ``SDIFF key [key ..]``，多个集合的差集运算。
* ``SINTER key [key ...]``，多个集合的交集运算。
* ``SUNION key [key ...]``，多个集合的并集运算。
* 集合类型键存储标签适合需要单独增加或删除标签的场合，且对标签的次序无任何要求。
* 如果是设置所有标签后一起上传提交，没有针对单个标签的操作，可以直接使用字符串类型键存储标签数据。
* 需要列出某个标签下的所有文章，或是同时属于某几个标签的文章列表，具体做法是为每个标签使用一个名为``tag:标签名称:posts`` 的集合类型键存储该标签的文章 ID 列表。（那不是可以随便乱存没有关联啊？）
* ``SCARD key``，获得集合中元素个数。
* ``SDIFFSTORE destination key [key ...]``、``SINTERSTORE destination key [key ...]``、``SUNIONSTORE destination key [key ...]``，进行集合运算并储存结果，常用与需要多步集合运算的场景中。
* ``SRANDMEMBER key [count]``，随机获取元素，count 为正不重复，count 为负可重复。
* 上述命令其实并不十分随机，因为采用散列表实现，散列表使用散列函数将元素映射到不同的存储位置（桶）上。
* 若散列值冲突，Redis 使用拉链法解决，即以链表的形式存入同一个桶中，查找元素时先随机找到桶，再从桶中随机查找元素；所以桶中的元素越少，取到的可能性就越大。
* ``SPOP key``，弹出一个元素，随机。

#### 3.6 有序集合类型

* 在集合类型的基础上，为集合中的每个元素关联了一个分数，能够在集合操作之外，获得分数最高（或最低）的前 N 个元素、获得指定分数范围内的元素等操作。

* 同列表类型的相似点：
  * 有序
  * 可以获得某一范围的元素
  
* 同列表类型的不同点：
  * 列表类型通过链表实现，获取两端的数据速度快，获取中间数据的速度慢；
  * 有序集合使用散列表和跳跃表实现，及时读取位于中间部分的数据速度也很快；
  * 列表不能简单地调整某个元素的位置，但有序集合可以（通过更改分数）；
  * 有序集合更加耗费内存。
  
* ``ZADD key score member [score member ...]``，用来向有序集合加入元素和分数，如果元素已存在则替换分数，返回值是新添加到集合中的元素数量。

* 分数不仅支持整数，还支持双精度浮点数，如 1.5、17E+307 等，-inf 和 +inf 分别表示负无穷和正无穷。

* ``ZSCORE key member``，获得元素的分数。

* ``ZRANGE key start stop``，获得排名在某个范围内的元素列表，需要同时获得分数的话可以在 ZRANGE 命令尾部加上 WITHSCORES 参数。

* ZRANGE 命令的时间复杂度为 O(log n+m)，n 为有序集合的基数，m 为返回的元素个数。

* 如果两个元素分数相同，按照字典顺序排列，中文则根据中文的编码方式排列。

* ``ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count]``，按照元素分数从小到大顺序返回分数在 min 和 max 之间（闭区间）的元素。

* 不希望闭区间，就在分数前面加上半括号 (。

* 支持无穷大，那就是全部输出来了。

* LIMIT offset count 表示在获得的元素列表基础上向后偏移 offset 个元素，并且只获取前 count 个元素。

* ``ZREVRANGEBYSCORE``，命令能够像 ZRANGEBYSCORE 一样但是是倒着输出的，然后 min 和 max 也是换位的；同理 ``ZREVRANGE`` 是从大到小的排列。

* ``ZREVRANGEBYSCORE scoreboard 100 0 LIMIT 0 3``。

* ``ZINCRBY key increment member``，可以增加一个元素的分数，返回值是更改后的分数。

* 实现点击量排序，点击量存储在 ``posts:page.view`` 的有序集合中，以 ID 为名称：

  ```
  $postsPerPage = 10
  $start = ($currentPage - 1) * $postPerPage
  $end = $currentPage * $postPerPage - 1
  $postID = ZREVRANGE posts:page.view, $start, $end
  for each $id in $posysID
  	$postData = HGETALL post:$id
  	print 文章标题：$postData.title
  ```

* 借助有序集合可以存储文章和文章时间，意味着时间是可以直接修改的。

* ``ZCARD key``，获得集合中元素的数量。

* ``ZCOUNT key min max``，获得指定分数范围内的元素个数，min 和 max 同 ZRANGEBYSCORE 的一样。

* ``ZREM key member [member ...]``，删除一个或多个元素。

* ``ZREMRANGEBYRANK key start stop``，按照元素分数从小到大的顺序删除元素。

* ``ZREMRANGEBYSCORE key min max``，按照元素分数范围删除元素。

* ``ZRANK key member``、``ZREVRANK key member``，获得元素的正反排名。

* ``ZINTERSTORE destination numkeys key [key ...] [WEIGHTS weight [weight ...]] [AGGREGATE SUM|MIN|MAX]``，计算多个有序集合的交集并将结果存储在 destination 键中，返回存储的元素个数。

* 当 AGGREGATE 为 SUM 时，交集为分数的和，MIN 和 MAX 字面意思。

* WEIGHTS 就是不同集合的权重，在参与交集的时候分数会乘上权重。



### Chapt 4 进阶

#### 4.1 事务

* 事务是一组命令的集合，事务中的命令要么都执行、要么都不执行。

* 基本使用：

  ```
  redis> MULTI
  OK
  redis> SADD "user:1:following" 2
  QUEUED
  redis> SADD "user:2:followers" 1
  QUEUED
  redis> EXEC
  ```

* 使用 MULTI 命令，告诉 Redis 下面的命令属于同一个事务。

* 返回 QUEUED 表示着两条命令已经进入等待执行的事务队列。

* 使用 EXEC 命令，告诉 Redis 开始执行事务内的命令。

* 事务可以保证命令依次执行且不被其他命令插入。

* Redis 中没有关系型数据库的回滚功能，某些错误的命令会在事务中依然执行。

* 在 GET 获得键值后保证该键值不被其他客户端修改，直到函数执行完成后才允许其他客户端修改该键值，可以避免竞态条件。

* 需要使用 WATCH 命令，可以监控一个或多个键，一旦其中有一个键被修改，之后的事务就不会执行。

* 监控一直持续到 EXEC 命令。

* 比如自己实现 INCR 函数的伪代码：

  ```
  def incr($key)
  	WATCH $key
  	$value = GET $key
  	if not $value
  		$value = 0
  	$value = $value + 1
  	MULTI
  	SET $key, $value
  	result = EXEC
  	return result[0]
  ```

* WATCH 命令的作用只是当被监控的键值被修改后阻止之后一个事务的执行，而不能保证其他客户端不修改这一键值，所以需要在 EXEC 执行失败后重新执行整个函数。

* 执行 EXEC 命令会取消对所有键的监控，也可以使用 UNWATCH 来取消监控。

* 实现 hsetxx 函数，同 HSETNX 类似：

  ```
  def hsetxx($key, $field, $value)
  	WATCH $key
  	$isFieldExists = HEXISTS $key, $field
  	if $isFieldExists is 1
  		MULTI
  		HSET $key, $field, $value
  		EXEC
  	else
  		UNWATCH
  	return $isFieldExists
  ```

#### 4.2 过期时间

* 有时效的数据，过了一定的时间就需要删除这些数据。

* 在关系数据库中一般需要额外的一个字段记录到期时间，然后定期监测删除过期数据。

* 在 Redis 中可以使用 EXPIRE 命令设置一个键的过期时间，到时间后 Redis 会自动删除它。

* EXPIRE 命令的使用方法为 ``EXPIRE key seconds``，其中 seconds 参数表示键的过期时间，单位是秒。

* EXPIRE 命令返回 1 即标识设置成功。

* TTL 命令可以得到还有多久时间会被删除，``TTL key``，键不存在则返回 -2。

* PERSIST 命令可以使设置过期时间的键变为永久的。

* SET 命令重新赋值也会取消过期时间。

* PEXPIRE 是更加精确的过期时间，单位为 1 毫秒，对应的查看时间命令是 PTTL。

* 实现访问频率限制，可以用 EXPIRE 命令。

  * 具体如要限制每分钟每个用户最多访问 100 个页面。
  * 思路是对每个用户使用一个名为 rate.limiting:用户 IP 的字符串类型键。
  * 每次用户访问则使用 INCR 命令增加键值。
  * 若递增后的值为 1，则同时设置该键的过期时间为 1min。
  * 这样每此用户访问页面时都读取该键的键值，如果超过了 100 就表明该用户的访问频率超过了限制，需要提示用户稍后访问。
  * 键每分钟都会自动删除，下一分钟用户的访问次数又重新计算。

  ```
  $isKeyExists = EXISTS rate.limiting:$IP
  if $isKeyExists is 1
  	$times = INCR rate.limiting:$IP
  	if $times > 100
  		print 访问频率超过了限制，请稍后再试
  		exit
  	else
  		MULTI
  		INCR rate.limiting:$IP
  		EXPIRE rate.limiting:$IP, 60
  		EXEC
  ```

* 如果要精确地每分钟都访问 100 次，而不是前一分钟的最后一秒访问 99 次，后一分钟的第一秒访问 99 次，变成两秒访问了 198 次。

* 因此，可以对每个用户建立一个列表类型，记录最近 100 次访问博客的时间，一旦超过 100 个，就判断时间最早的元素距离现在的时间是否小于 1 min。

* 就不是用 EXPIRE 的方法了。

  ```
  $listLength = LLEN rate.limiting:$IP
  if $listLength < 10
  	LPUSH rate.limiting:$IP, now()
  else
  	$time = LINDEX rate.limiting:$IP
  	if now() - $time < 60
  		print 访问频率超过了限制，请稍后再试。
  	else
  		LPUSH rate.limiting:$IP, now()
  		LTRIM rate.limiting:$IP, 0, 9
  ```

* 不过如果次数较多，会占用较多的存储空间，实际使用还需要权衡。

* 此外还会出现竞态条件，可以用脚本功能避免。

**实现缓存**

* 提高网站负载能力，需要将访问频率较高但对 CPU 或 IO 资源消耗较大的操作结果缓存起来，并希望让这些缓存过一段时间自动过期。

* 比如教务网页对全校同学成绩汇总排名，计算过程较耗资源，可以将结果通过 Redis 的字符串键缓存起来。

* 不过学生的成绩总在不断变化，每隔两个小时就要更新一次，那么可以给键设置过期时间的方式实现。

* 访问时，如果键存在，那么直接使用缓存的值；如果键不存在，就重新计算排名并将计算结果赋值给该键，同时设置过期时间为两个小时。

* 伪代码如下：

  ```
  $rank = GET cache:rank
  if not $rank
  	$rank = 计算排名...
  	MULTI
  	SET cache:rank, $rank
  	EXPIRE cache:rank, 7200
  	EXEC
  ```

* 不过，当服务器内存有限时，大量使用长期缓存就会导致内存爆满，而使用短期缓存又无法满足要求。

* 因此，实际开发中会限制 Redis 能够使用的最大内存，并让 Redis 按照一定贵族淘汰不需要的缓存键，这种方式在只将 Redis 用作缓存系统时非常实用。

* 具体方法为，修改配置文件的 maxmemory 参数，单位是字节。

* 超出限制后 Redis 会根据 maxmemory-policy 参数指定的策略删除不需要的键直到 Redis 占用内存小于核定内存。

* 策略支持：

  * volatile-lru：使用 LRU 删除（只对设置了过期时间的键），最近最少使用算法。
  * allkeys-lru：使用 LRU 删除一个键
  * volatile-random：随机删除一个键（只对设置了过期时间的键）
  * allkeys-random：随即删除一个键
  * volatile-ttl：删除过期时间最近的一个键
  * noeviction：不删除只返回错误

#### 4.3 排序

**有序集合的集合操作**

* 有序集合常见的使用场景是大数据排序，如游戏玩家的排行榜，很少使用到键中的全部数据。

* 如果需要 ZINTER 的命令，可以使用事务：

  ```
  MULTI
  ZINTERSTORE tempKey ...
  ZRANGE tempKey ...
  DEL tempKey ...
  EXEC
  ```

**SORT 命令**

* SORT 命令可以对列表类型、集合类型和有序集合类型键进行排序，并且可以完成与关系数据库中链接查询相类似的任务。

* 在集合键中，集合元素是无序的，可以借助 SORT 命令实现。
* ``SORT key``，可以直接对键内的内容排序，其中有序集合只对本身排序忽略分数。
* ``SORT key ALPHA``，可以通过 ALPHA 参数实现按照字典顺序排列非数字元素。
* SORT 命令的 DESC 参数可以实现将元素按照从大到小的顺序排列。
* SORT 命令的 LIMIT offset count 参数，表示跳过前 offset 个元素并获取之后的 count 个元素。

**BY 参数**

* SORT 命令的 BY 参数，可以设置元素排序的参照，对每个元素使用元素的值替换参考键中的第一个 * 并获取其值，不过这个 \* 只能用在键名上，如 ``SORT tag:ruby:posts BY post:*->time DESC``。
* 除了散列类型外，参考键还可以是字符串类型，如果 BY 的是常量键名的话就会无事发生。
* 如果参考键值相同，则 SORT 命令会再比较元素本身的值来决定元素的顺序。
* 某个元素的参考键不存在时，会默认参考键的值为 0。

**GET 参数**

* SORT 命令的 GET 参数，可以使 SORT 命令的返回结果不再是元素自身的值，而是 GET 参数中指定的键值，使用规则和 BY 参数一样。
* ``SORT tag:ruby:posts BY post:*->time DESC GET post:*->title``，返回的就是 title 了。
* SORT 命令中可以有多个 GET 参数，如果要返回排序元素自身，就使用 GET # 参数。

**STORE 参数**

* SORT 的 STORE 参数会把结果保存到指定的键中，不过保存的是列表类型。

* STORE 参数常用来结合 EXPIRE 命令缓存排序结果。

  ```
  # 判断是否存在之前排序结果的缓存
  $isCacheExists = EXISTS cache.sort
  if $isCacheExists is 1
  	# 如果存在则直接返回
  	return LRANGE cache.sort, 0, 1
  else
  	# 如果不存在，则使用 SORT 命令排序并将结果保存到 cache.sort 键中作为缓存
  	$sortResult = SORT some.list STORE cache.sort
  	EXPIRE cache.sort, 600
  	return $sortResult
  ```

**性能优化**

* SORT 是 Redis 最强大也最复杂的命令之一，如果使用不好很容易成为性能瓶颈。
* SORT 命令的时间复杂度为 O(n+mlog(m))，其中 n 表示要排序的列表（集合或有序集合）中的元素个数，m 表示要返回的元素个数。
* 当 n 较大时 SORT 性能相对较低，并且 Redis 在排序前会建立一个长度为 n 的容器来存储待排序的元素。
* 需要注意：
  * 尽可能减少待排序键中元素的数量（n 小）
  * 使用 LIMIT 参数获取需要的数据（m 小）
  * 要排序的数据量较大，尽可能使用 STORE 保存结果缓存

#### 4.4 消息通知

**任务队列**

* 发送邮件时为避免用户等待太久，使用独立的线程来完成。
* 线程实现困难，可以通知其他进程向指定的地址发送邮件，通知的过程可以借助任务队列来实现。
* 与任务队列进行交互的实体有两类，一类是生产者，另一类是消费者，前者将任务放入任务队列中，后者则读取任务并执行。
* 使用任务队列的好处：
  * 松耦合，生产者和消费者无需知道彼此的实现细节，只需要约定好任务的描述格式。
  * 易于扩展，消费者可以有多个、分布在不同服务器中，降低单台服务器的负载。

**使用 Redis 实现任务队列**

* 自然使用 Redis 的列表类型，使用 LPUSH 和 RPOP 命令。

* 伪代码：

  ```
  # 无限循环读取任务队列中的内容
  loop
  	$task = RPOP queue
  	if $task
  		# 如果任务队列中有任务则执行
  		execute($task)
  	else
  		# 如果没有则等待 1 秒以免过于频繁地请求数据
  		wait 1 second
  ```

* 就算没有任务，消费者也会无限次的调用 RPOP 命令。

* BRPOP 命令可以实现一旦有新任务加入队列就通知消费者。

* BRPOP 命令会一直阻塞住连接，直到有新的元素加入：

  ```
  loop
  	# 如果没有新任务，BRPOP 会一直阻塞，不会执行
  	$task = BRPOP queue, 0
  	# 返回值是一个数组，数组的第二个元素是人物
  	execute($task[1])
  ```

* BRPOP 命令接收两个参数，第一个是键名，第二个是超时时间，单位是秒。

* 当超过设定时间后会返回 nil，设置为 0 就永远阻塞。

* 返回两个值，分别是键名和元素值。

* BLPOP 同一个意思啦。

**优先级队列**

* 当做某一件事存在优先顺序时，可以实现优先级队列。

* BRPOP 命令可以同时接受多个键，``BRPOP key [key ...]``，如 ``BRPOP queue:1 queue:2 0``。

* 意义是同时检测多个键，如果所有键都没有元素则阻塞，否则有一个就弹出。

* 多个键都有元素的话就按照从左到右顺序取第一个键中的一个元素。

* 以此特性可以实现区分优先级的任务队列，分别存储不同优先级的邮件通知。

  ```
  loop
  	$task = BRPOP queue:confirmation.email, queue:notification.email, 0
  	execute($task)
  ```

**发布/订阅模式**

* Redis 还提供了一组命令可以让开发者实现“发布/订阅”（publish/subscribe）模式。
* 该模式同样可以实现进程间的消息传递。
* 该模式中包含两种角色，分别是发布者和订阅者，订阅者可以订阅若干个频道（channel），而发布者可以向指定的频道发送消息，所有订阅此频道的订阅者都会收到此消息。
* 发布者的命令是 PUBLISH，``PUBLISH channel message``，如 ``PUBLISH channel.1 hi``。
* PUBLISH 命令的返回值表示接收到这条消息的订阅者数量。
* 发布的消息不会被持久化，也就是说当有客户端订阅 channel.1 后，只能收到后续发布到该频道的消息，之前发送的就收不到了。
* 订阅频道的命令是 SUBSCRIBE，``SUBSCRIBE channel [channel ...]``。
* 命令运行后处于订阅状态，不能使用除了 SUBSCRIBE UNSUBSCRIBE PSUBSCRIBE PUNSUBSCRIBE 外的命令。
* 订阅状态的客户端会收到 3 种类型的回复，每种类型包含 3 个值：
  1. subscribe；表示订阅成功的反馈信息，第二个值是频道名称，第三个值是订阅频道的数量。
  2. message；接收到的消息，第二个值是产生消息的频道名称，第三个只是消息内容。
  3. unsubscribe；成功取消订阅某个频道，第二个值是对应的频道名称，第三个是当前订阅频道的数量，为 0 则退出订阅状态。

**按照规则订阅**

* PSUBSCRIBE 命令订阅指定的规则，支持 glob 风格的通配符格式。
* 返回四个值，第一个表明通过 PSUBSCRIBE 收到的，第二个是通配符，第三个是频道名，第四个是消息值。
* PSUBSCRIBE 可以重复订阅一个频道，并返回多次消息通知。
* ``PUNSUBSCRIBE pattern``，可以退订制定规则，没有参数会退订所有规则。
* P 的命令不会影响 S 的命令。

#### 4.5 管道

* 客户端和 Redis 使用 TCP 协议连接，经过网络传输需要往返延时。
* 网络性能不同，往返时延也不相同，大致来说本地回环地址的往返时延在数量级上大致为 Redis 一条简单命令。
* Redis 底层通信协议对管道进行支持。
* 通过管道可以一次性发送多条命令并在执行完成后一次性将结果返回。
* 当一组命令中每条命令都不依赖于之前命令的执行结果时就可以将这组命令一起通过管道发出，减少同 Redis 的通信次数。

#### 4.6 节省空间

**精简键名和键值**

* 是最直观的减少内存占用的方式，但还是要把握好尺度。
* 存储用户性别的字符串类型键取值为 male 和 female，可以修改成 m 和 f 来节约字节，更好的方法是 0 和 1。

**内部编码优化**

Redis 根据内部编码规则来节省更多空间。

为每种数据类型提供了两种内部编码方式，在元素少时可能会使用更为紧凑但性能稍差的编码方式。

对开发者来说是透明的。

查看内部编码方式可以使用 OBJECT ENCODING 命令。

Redis 键值都是使用 redisObject 结构体保存的：

```
typedef struct redisObject {
	unsigned type;
	unsigned notused;
	unsigned encoding;
	unsigned lru;
	int refcount;
	void *ptr;
}
```

type 字段表示的是键值的数据类型。

encoding 表示的是 Redis 键值的内部编码方式，同 type 都通过宏定义固定的值。

字符串类型：

* 使用 sdshdr 类型变量来存储字符串，redisObject 的 ptr 字段指向该变量的地址。

  ```
  struct sdshdr {
  	int len;
  	int free;
  	char buf[];
  };
  ```

* len 字段表示字符串的长度，free 字段表示 buf 中的剩余空间，buf 存储字符串的内容。

* 如果键值内容可以用 64 位有符号整数表示，Redis 会将键值转换成 long 类型来存储。

* 若存储 ``SET key foobar``，需要 ``sizeof(redisObject) + sizeof(sdshdr) + strlen("foobar")`` 30 字节；存储 ``SET key 123456`` 占用空间为 ``sizeof(redisObject)`` 16字节。

* refcount 字段存储该键值被引用的数量。

* Redis 启动后会预先建立 10000 个分别存储 0 到 9999 数字的 redisObject 类型变量作为共享对象。

* 如果要设置的字符串键值在 10000 个数字内，那么直接引用共享对象就可以，存储键值占用 0 字节。

* 因此，存储 ID 之类的值非常节省存储空间。

* 当通过配置文件参数 maxmemory 设置了 Redis 可用空间时，Redis 不会使用共享对象。

* REDIS_ENCODING_EMBSTR 编码存储字符串，sdshdr 结构体与对应的分配在同一块连续的内存中。

* 内存连续，操作更加边界，缓存更好发挥作用。

* 当键值内容不超过 39 字节，会采用上述编码方式，在修改操作、或是较大空间时会改为 REDIS_ENCODING_RAW。

散列类型：

* REDIS_ENCODING_HT 或 REDIS_ENCODING_ZIPLIST。

* 在配置文件中可以设置后者编码方式的时机，hash-max-ziplist-entries、hash-max-ziplist-value。

* 字段个数少于 entries 参数且字段名、字段值小于 value 时，使用 ZIPLIST 存储。

* 转换过程是透明的。

* HT 编码即散列表，实现 O(1) 的操作，使用 redisObject 存储的，字符串优化方法同样适用于此。

* 数据库中的数据通过结构体 redisDb 存储：

  ```
  typedef struct redisDb {
  	dict *dict;				// The keyspace for this DB
  	dict *expires;			// Timeout of keys with a timeout set
  	dict *blocking_keys;	// Keys with clients waiting for data (BLPOP)
  	dict *ready_keys;		// Blocked keys that received a PUSH
  	dict *watched_keys;		// WATCHED keys for MULTI/EXEC CAS
  	int id;
  } redisDb; // dict 是散列表结构
  ```

* ZIPLIST 是紧凑的编码格式，牺牲部分读取性能换取极高的空间利用率，同样在列表类型和有序集合类型中使用。

* 编码结构：

  * zlbytes、zltail、zllen、元素1、元素2、...、zlend；
  * 元素内部则为，前一个元素的大小、当前元素的编码类型、当前元素的大小、当前元素的内容。

* zlbytes 表示整个结构占用的空间，zltail 表示到最后一个元素的偏移，zllen 是元素的数量，zlend 标记结构的末尾且值永远为 255。

* ZIPLIST 每个元素由四个部分组成：

  * 第一部分用来存储前一个元素的大小，以实现倒序查找；
  * 第二、三个部分是元素的编码类型和元素的大小；
  * 第四个部分是元素的实际内容；
  * 当元素满足一定条件，都可以再缩小成更小的。

* 可以预见，直接顺序遍历的 ZIPLIST 在元素数量较多时性能较差。

列表类型：

* REDIS_ENCODING_LINKEDLIST 或 REDIS_ENCODING_ZIPLIST。
* LINKEDLIST 是双向链表，每个元素是用 redisObject 存储的，优化方法同字符串类型的键值相同。
* ZIPLIST 同散列类型相似，不过查找两端的数据依然较快。
* 新版本 Redis 增加了 REDIS_ENCODING_QUICKLIST 将两者结合，原理是将一个长列表分成若干个以链表形式组织的 ziplist。

集合类型：

* REDIS_ENCODING_HT 或 REDIS_ENCODING_INTSET。

* 当集合中所有元素是整数且元素的个数小于配置文件中的 set-max-intset-entries 参数指定值会使用 INTSET。

* intset 结构定义：

  ```c
  typedef struct intset {
      uint32_t encoding;	// 缺省 INTSET_ENC_INT16 2 个字节，新增加的元素超过 2 字节就升为 INT32 并调整之前所有元素的位置和长度，INT64 也可行
      uint32_t length;
      int8_t contents[];	// 集合中的元素值
  } intset;
  ```

* 超过指定值就转变为 REDIS_ENCODING_HT。

有序集合类型：

* REDIS_ENCODING_SKIPLIST 或 REDIS_ENCODING_ZIPLIST。
* 后者和散列类型及列表类型一样。
* 前者使用散列表和跳跃列表两种数据结构来存储有序集合类型键值。
* 前者实现 O(1) 时间复杂度 ZSCORE 等命令，后者用来存储元素的分数及其到元素值的映射以实现排序的功能。
* Redis 对跳跃列表实现进行了修改，比如允许元素相同，以及跳跃链表结点增加指向前的元素指针实现倒序查找。
* SKIPLIST 以 redisObject 存储，可以使用字符串类型键值的优化方式。
* 元素分数用 double 类型存储。

跳跃链表

![img](https://img-blog.csdn.net/20150530162529554?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveWFuZ195dWxlaQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

随机化数据结构，基于并联的链表，效率可以比拟与二叉查找树。

跳跃列表是对有序链表增加上附加的前进链接，增加以随机化方式进行。

因此可以快速跳过部分列表元素，所有操作都以对数随机化的时间进行。

每个结点都包含多个指向后续元素的指针，而且这一过程通过随机函数生成器得到。

```c
int random_level() {
    int level = 1;
    while (rand() % 2) {
        level++;
    }
    level = (level < MAX_LEVEL) ? level : MAX_LEVEL;
    return level;
}
```

链表元素：

```c
typedef struct NODE {
    T data;
    struct Node *next[i]; // 指向后继元素的指针
}
```

主要逻辑：

* 从高层开始查找直到等于指定元素的节点 E 或者第一个大于指定元素的节点 G；
* 若是 E 直接返回；
* 若是 G，就以前一个节点 L，在下一层进行查找；
* 重复逻辑直到找到 E。

明天再看。



### Chapt 5 实践

#### 5.1 PHP 与 Redis

#### 5.2 Ruby 与 Redis

#### 5.3 Python 与 Redis

#### 5.4 Node.js 与 Redis



### Chapt 6 脚本

#### 6.1 概览

4.2.2 节实现了访问频率限制功能：

* 竞态条件，解决方法是用 WATCH 命令检测键的变动；
* 使用 WATCH 需要判断事务是否因为键被改动而没有执行；
* 另外在不使用管道的情况下最多要向 Redis 七请求 5 条命令，传输耗时较大。

使用 Redis 脚本功能定义新的命令。

Redis 内部包含了 Lua 解释器。

**脚本介绍**

在 Lua 脚本中可以调用大部分 Redis 命令。

使用脚本的好处：

1. 较少网络开销：使用脚本完成访问频率限制只需要发送一个请求，减少网络往返时延；
2. 原子操作：Redis 会将整个脚本作为一个整体执行，中间不会被其他命令插入，无须担心竞态条件，无需使用事务；
3. 复用：客户端发送的脚本会永久存储在 Redis 中，意味着其他客户端（或是语言）可以复用脚本而不需要重写。

**实例：访问频率限制**

无需考虑事务，Redis 脚本实现访问频率限制很简单。

```lua
local times = redis.call('incr', KEYS[1])
if time == 1 then
    -- KEYS[1] 键刚创建，所以为其设置生存时间
    redis.call('expire', KEYS[1], ARGV[1])
end
if times > tonumber(ARGV[2]) then
    return 0
end
return 1
```

脚本运行：``redis-cli --eval /path/to/ratelimiting.lua rate.limiting:127.0.0.1 , 10 3``。

其中，``/path/to/ratelimiting.lua`` 是脚本的路径，后面是传递的参数；其中 ``,`` 前面的是要操作的键，可以在脚本中使用 KEYS[1] 获取，``,`` 后面的 10 和 3 是参数，在脚本中能够使用 ARGV[1] 和 ARGV[2] 获得。

若在终端多次运行上述脚本，输出会从 1 变成 0。

注意到 ``,`` 两边的空格不能省略，否则会出错。

#### 6.2 Lua 语言

Lua 是一个高效的轻量级脚本语言。

编写需要逻辑的 Lua 脚本，然后在程序中嵌入一个 Lua 解释器，每次需要就调用该脚本，而不需要更新程序服务；越多的逻辑放在校本上，程序的升级和扩展就越简单。

**Lua 语法**

数据类型：

* 空（nil），所有没有赋值的变量或表的字段都是 nil。
* 布尔（boolean），布尔类型包含 true 和 false 两个值。
* 数字（number），整数和浮点数都是使用数字类型存储，如 1、0.2、3.5e20 等。
* 字符串（string），存储字符串，且和 Redis 键值一样是二进制安全的。可以用单引号或双引号表示，也可以转义字符。
* 表（table），表是 Lua 中唯一的数据结构，既可以当数组又可以当字典。
* 函数（function），函数在 Lua 中是一等值，可以存储在变量中、作为函数的参数或返回结果。

二进制安全：

* 二进制安全以为传递什么样的二进制，存储的就是什么样的二进制。
* Redis 二进制安全的好处，存取都按字节，没有类型，不会变化存储数据，不会有溢出和覆盖，不会有乱码问题。
* 要注意编码格式统一的问题。

变量：

* 分为全局变量和局部变量；全局无需声明直接使用，默认值为 nil（未赋值直接使用）。

* Redis 脚本中不能使用全局变量，只允许使用局部变量防止脚本间相互影响。

* 声明局部变量的方法：

  ```lua
  local c		-- 声明局部变量 c，默认值 nil
  local d = 1	-- 声明局部变量 d，赋值为 1
  local e, f	-- 同时声明多个局部变量
  local say_hi = function ()
      print 'hi'
  end			-- 声明一个匿名函数的局部变量
  ```

* 变量名非数字开头，字母、数字、下划线，不能为关键字。

* 作用域同其他语言。

注释：

* 单行注释以 ``--`` 开始。
* 多行注释以 ``--[[`` 开始，到 ``]]`` 结束。

赋值：

* Lua 支持多重赋值，同 Go 差不多。
* 多重赋值会先计算所有表达式的值，再进行赋值。

操作符：

* 数学操作符 +-*/%-^ 等，如果操作数字符串会自动转化成数字。
* 比较操作符 == ~= < > <= >=，不会进行自动类型转换。
* 使用 tonumber 和 tostring 可以进行字符串数字转换，前者传入两个参数还可以根据后一个进行进制转换。
* 逻辑操作符 not and or，支持短路即 and 操作符从左到右判断。
* 连接操作符 .. 用来连接两个字符串。
* 取长度操作符 #，获取字符串或表的长度。

if 语句：

* 格式：

  ```lua
  if 条件表达式 then
      语句块
  end
  elseif 条件表达式 then
  	语句块
  end
  else
  	语句块
  end
  ```

* 对于 Redis 返回的整数 0 或 1，Lua 语言都会认为是真，因此要用 == 来判断。

循环语句：

* while、repeat、for

* while 语句：

  ```lua
  while 条件表达式 do
      语句块
  end
  ```

* repeat 语句：

  ```lua
  repeat
      语句块
  until 条件表达式
  ```

* for 语句：

  ```lua
  for 变量=初值, 终值, 步长 do  -- 步长可以省略默认为 1
      语句块
  end
  for 变量 1, 变量 2, ..., 变量 N in 迭代器 do
      语句块
  end
  ```

表类型：

* 可以理解为关联数组，任何类型的值都可以作为表的索引。

  ```lua
  a = {}
  a['field'] = 'value'
  print(a.field)
  people = {
      name = 'Bob',
      age = 29
  }
  ```

* 索引为整数时表和传统数组一样，约定索引从 1 开始。

  ```lua
  for index, value in ipairs(a) do
      print(index)
      print(value)
  end
  ```

* ipairs 是 Lua 内置函数，实现类似迭代器的功能。

* 也可以这样来：

  ```lua
  for i = 1, #a do
      print(i)
      print(a[i])
  end
  ```

函数：

* 定义方式：

  ```lua
  function (参数列表)
      函数体
  end
  ```

* 可以赋值给局部变量，可以用语法糖定义函数：

  ```lua
  local function square(num)
      return num * num
  end
  ```

* 实参个数小于形参则多的形参为 nil，反之多的实参会被忽略；希望捕获多出的实参可以让最后一个形参为 ...。

return 和 break（用于跳出循环）语句必须是语句块中的最后一条语句，后面只能是 end else until；可以人为用 do 和 end 将其包围。

**标准库**

String 库：

* 可以通过字符串类型的变量以面向对象的形式访问，如 string.len(string_var) 可以写成 string_var:len()。
* 获取字符串长度，``string.len('hello')``，作用和 # 类似。
* 转换大小写，``string.lower('hello')``、``string.upper('HELLO')``。
* 获取子字符串，``string.sub('hello', 1, 2)``，闭区间，第三个参数可以省略。

Table 库：

* 大部分函数都需要表的形式是数组形式。
* 将数组转换成字符串，``table.concat({1, 2, 3}, sep, start, end)``，默认为 1 和表长。
* 向数组中插入元素，``table.insert({1, 2, 3}, pos, value)``，默认数组尾部插入。
* 从数组中弹出一个元素，``table.remove(table, pos)``。

Math 库：

* 常用的数学运算函数，abs sin cos tan ceil floor max min pow sqrt。
* 随机函数，``math.randomseed(x)`` ``math.random([m, [, n]])``：
  * 不提供参数，返回 [0, 1) 实数；
  * 提供 m 参数，返回 [1, m] 整数；
  * 提供 m n 参数，返回 [m, n] 整数。

**其他库**

cjson 库和 cmsgpack 库提供了对 JSON 和 MessagePack 的支持。

Redis 自动加载了两个库，脚本中可以通过 cjson 和 cmsgpack 来访问对应的库。

#### 6.3 Redis 与 Lua

编写 Redis 脚本的目的就是读写 Redis 数据。

**在脚本中调用 Redis 命令**

在脚本中可以使用 redis.call 函数调用 Redis 命令，返回值就是命令的执行结果。

```lua
redis.call('set', 'foo', 'bar')
local value = redis.call('get', 'foo') -- value 的值为 bar
```

redis.call 函数会将返回的 5 中类型转换成对应 Lua 的数据类型。

| Redis 返回值类型 | Lua 数据类型                            |
| ---------------- | --------------------------------------- |
| 整数回复         | 数字类型                                |
| 字符串回复       | 字符串类型                              |
| 多行字符串回复   | 表类型（数组形式）                      |
| 状态回复         | 表类型（只有一个 ok 字段存储状态信息）  |
| 错误回复         | 表类型（只有一个 err 字段存储错误信息） |

Redis 还提供了 redis.pcall 函数，惟一的区别是当命令执行出错时 redis.pcall 会记录错误并继续执行，而 redis.call 会直接返回错误不继续执行。

**从脚本中返回值**

脚本中可以使用 return 语句将值返回给客户端，如果没有执行 return 语句则默认返回 nil。

返回值和前面所述的相似。

**脚本相关命令**

EVAL 命令：

* Redis 提供了 EVAL 命令可以使开发者调用其他 Redis 内置命令一样调用脚本。
* 类似 ``EVAL "return redis.call('SET', KEYS[1], ARGV[1])" 1 foo bar``。
* ``EVAL 脚本内容 key参数数量 [key ...] [arg ...]``。
* 命令中的参数数量不能省略，就算为 0。

EVALSHA 命令：

* 考虑到脚本较长的情况下，每次调用需要将脚本传递占用较多带宽。
* EVALSHA 命令允许开发者通过脚本内容的 SHA1 摘要来执行脚本。
* 执行 EVAL 命令时会计算脚本的 SHA1 摘要并记录在脚本缓存中，执行 EVALSHA 就会从脚本缓存中查找对应内容。
* 流程：
  1. 计算脚本 SHA1 摘要，并使用 EVALSHA 命令执行脚本。
  2. 获得返回值，如果返回 “NOSCRIPT” 错误就是用 EVAL 命令重新执行脚本。
* 很多编程语言的 Redis 客户端会代替开发者完成这一流程。

**应用实例**

不是 Go 语言的。Ignore！

#### 6.4 深入脚本

**KEYS 与 ARGV**

可以不按照规定传递参数，但是在某些情况下会出现错误，比如无法使用集群功能等。

如果键名根据脚本某部分执行结果生成，无法在执行前将键名明确标出。

比如：

```lua
local sum = 0
local usrs = redis.call('SMEMBERS', KEYS[1])
for _, user_id in ipairs(users) do
    local user_age = redis.call('HGET', 'user:' .. user_id, 'age')
    sum = sum + user_age
end
return sum / #users
```

无法兼容集群，因为第 4 行访问了 KEYS 变量中没有的键，但能够避免数据往返客户端和服务端的开销。

**沙盒与随机数**

Redis 脚本禁止使用 Lua 标准库与文件或系统调用相关的函数，只允许对 Redis 的数据进行处理。

Redis 还通过禁用脚本的全局变量的方式保证每个脚本都是相对隔离的，不会互相干扰。

使用沙盒不仅是为了保证服务器的安全性，而且还确保了脚本执行结果只和脚本本身和执行传递的参数有关，不依赖外界条件（如系统时间、系统中某个文件的内容、其他脚本执行结果等）。

除了使用沙盒，为了确保执行结果可以重现，Redis 还对随机数和会产生的随机结果进行了特殊处理。

比如 math.random 和 math.randomseed 函数使得每次执行的随机数列都相同。

希望获得不同的随机数序列，就从调用的程序里获得，或是将随机种子传递到脚本中。

会产生随机结果的 SMEMBERS 或 HKEYS 等 Redis 会按照字典顺序排序，内部通过调用 Lua 标准库的 table.sort 函数实现的。

**其他脚本相关命令**

开发者较少使用到。

SCRIPT LOAD：将脚本加入缓存 ``SCRIPT LOAD "return 1"``。

SCRIPT EXISTS：判断脚本是否已经被缓存 ``SCRIPT EXISTS SHA1值 ...``。

SCRIPT FLUSH：清空脚本缓存 ``SCRIPT FLUSH``。

SCRIPT KILL：强制终止当前脚本执行 ``SCRIPT KILL``。

**原子性和执行时间**

Redis 的脚本执行是原子的，即脚本执行期间 Redis 不会执行其他命令。

为了防止某个脚本执行时间过长（如陷入死循环），Redis 提供了 lua-time-limit 参数限制脚本运行的最长时间。

超过设置时间后，Redis 会接受其他命令但不会执行，而是返回 BUSY 错误。

执行 ``SCRIPT KILL`` 命令可以终止当前脚本的运行，但如果脚本对 Redis 数据进行了修改，那么 SCRIPT KILL 命令不会终止脚本运行。

此时只能通过 ``SHUTDOWN NOSAVE`` 命令强行终止 Redis，意味着不会进行持久化操作，所有发生在上一次快照后 的数据库修改都会丢失。

脚本功能强大、性能优异，因此开发者需要开率把哪些任务交给脚本，通常来讲不应该在脚本中进行大量耗时的计算。



### Chapt 7 持久化

Redis 强劲性能很大程度上是由于其将所有数据存储在了内存中，然而当 Redis 重启后，所有存储在内存中的数据就会丢失。

我们希望 Redis 在重启后能够保证数据不丢失，如：

1. 将 Redis 作为数据库使用时。
2. 将 Redis 作为缓存服务器，但缓存被穿透后会对性能造成较大影响，所有缓存同时失效会导致缓存雪崩，使服务器无法响应。

持久化就是将数据从内存中以某种形式同步到硬盘中，使得重启后可以根据硬盘中的记录恢复数据。

支持两种方式的持久化，一种是 RDB 方式，另一种是 AOF方式。

前者会根据指定规则“定时”将内存中的数据存储在硬盘上，而后者在每次执行命令后将命令本身记录下来。

更多情况下是两者结合使用。

#### 7.1 RDB 方式

RDB 方式通过快照（snapshotting）完成的。

当符合一定条件时 Redis 会自动将内存中的所有数据生成一份副本存储在硬盘上，该过程即为“快照”。

在以下几种情况会进行快照：

1. 根据配置规则进行自动快照；
2. 用户执行 SAVE 或 BGSAVE 命令；
3. 执行 FLUSHALL 命令；
4. 执行复制（replication）时。

**根据配置规则进行自动快照**

配置文件中自定义，由两个参数构成：时间窗口 M 和改动的键个数 N。

当时间 M 内被更改的键的个数大于 N 时，即符合自动快照条件。

```
save 900 1
save 300 10
save 60 10000
```

条件之间是“或”的关系。

**用户执行 SAVE 或 BGSAVE 命令**

SAVE：同步地进行快照操作，会阻塞所有来自客户端的请求，数据较多时会导致较长时间不响应。

BGSAVE：推荐使用，异步地进行快照操作；执行后会返回 OK 表示开始执行快照操作，LASTSAVE 命令能够获取最近一次成功执行快照的时间。

**执行 FLUSHALL 命令**

执行该命令，Redis 会清除数据库中所有数据。

不论是否触发自动快照条件，只要自动快照条件不为空，Redis 就会执行快照操作。

如果没有定义自动快照条件，执行 FLUSHALL 不会进行快照。

**执行复制时**

设置了主从模式，Redis 会在复制初始化时进行自动快照。

关于主从模式和复制的过程会在第 8 章详细介绍。

**快照原理**

理清 Redis 实现快照的过程对我们了解快照文件的特性有很大帮助。

默认快照文件存储在 Redis 当前进程的工作目录中 dump.rdb 文件，可以通过配置 dir 和 dbfilename 两个参数分别指定快照文件的存储路径和文件名。

快照的过程：

1. Redis 使用 fork 函数复制一份当前进程（父进程）的副本（子进程）；
2. 父进程继续接收并处理客户端发来的命令，而子进程开始将内存中的数据写入硬盘中的临时文件；
3. 当子进程写入完所有数据后会用临时文件替换旧的 RDB 文件，至此一次快照操作完成。

在执行 fork 的时候操作系统（类 Unix 操作系统）会使用写时复制（copy-on-write）策略，即 fork 函数发生的一刻父子进程共享同一内存数据。

当父进程要更改其中某片数据时（如执行一个写命令），操作系统会将该片数据复制一份以保证子进程的数据不受影响，所以新的 RDB 文件存储的是执行 fork 一刻的内存数据。

写时复制策略也保证了在 fork 的时刻虽然看上去生成了两份内存副本，但实际上内存的占用量并不会增加一倍。

确保 Linux 系统允许应用程序申请超过可用内存（物理内存和交换分区）的空间，方法是在 /etc/sysctl.conf 文件加入 vm.overcommit_memory = 1，然后重启系统或者执行 sysctl vm.overcommit_memory = 1 确保设置生效。

当进行快照的过程中，如果写入操作较多，造成 fork 前后数据差异较大，是会使得内存使用量显著超过实际数据大小的，因为内存中不仅保存了当前的数据库数据，而且还保存着 fork 时刻的内存数据。

进行内存用量估算时很容易忽略这一问题，造成内存用量超限。

通过上述过程可以发现 Redis 在进行快照的过程不会修改 RDB 文件，只有快照结束后才会将旧的文件替换成新的，也就是说任何时候 RDB 文件都是完整的。

使得可以通过定时备份 RDB 文件来实现 Redis 数据库备份。

RDB 文件是经过压缩（可以配置 rdbcompression 参数以禁用压缩节省 CPU 占用）的二进制格式，所以占用的空间会小于内存中的数据大小，更加利于传输。

1000 万个字符串类型键、大小为 1 GB 快照文件载入到内存中需要花费 20-30 秒。

RDB 的持久化，一旦 Redis 异常退出，就会丢失最后一次快照以后更改的所有数据。

如果不希望有所损失，将损失降到最小则需要使用 AOF 方式进行持久化。

#### 7.2 AOF 方式

Redis 存储非临时数据时，打开 AOF 持久化降低进程中止导致的数据丢失。

AOF 可以将 Redis 执行的每一条命令追加到硬盘文件中，但会降低性能（可接收），另外使用较快的硬盘可以提高 AOF 性能。

**开启 AOF**

默认关闭，可以在配置上开启 ``appendonly yes``。

修改参数，``appendfilename appendonly.aof`` 可以改变 AOF 文件的保存位置和 RDB 文件的位置相同。

开启 AOF 持久化后每执行一条会更改 Redis 中的数据的命令，Redis 就会将该命令写入硬盘中的 AOF 文件。

**AOF 的实现**

会记录冗余的命令，因此 AOF 文件的大小也会越来越大，即使内存中实际的数据可能并没有多少。

不过，Redis 也会自动优化重写 AOF 文件，在配置文件中设置：

```
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb
```

前者意义是当 AOF 大小超过上一次重写时的 AOF 文件大小的百分之多少时会再次进行重写。

后者限制了允许重写的最小 AOF 文件大小。

也可以使用 ``BGREWRITEAOF`` 命令手动执行 AOF 重写。

启动 Redis 会逐个执行 AOF 文件中的命令来将硬盘中的数据载入到内存，载入的速度相较 RDB 会慢一些。

**同步硬盘数据**

执行更改数据库内容操作，AOF 都会将命令记录在 AOF 文件中，实际上写入硬盘缓存。

默认情况每 30 秒执行一次同步操作，将内容真正写入硬盘，可以自己配置，一般 30 秒是无法容忍的。

通过 ``appendfsync everysec`` 配置文件配置。

Redis 允许同时开启 AOF 和 RDB，既保证了数据安全又使得进行备份等操作十分容易。



### Chapt 8 集群

现实中的项目通常需要若干 Redis 服务器的支持：

1. 从结构上，单个 Redis 服务器会发生单点故障，同时一台服务器需要承受所有的请求负载，需要为数据生成多个副本并分配在不同的服务器上。
2. 从容量上，三个 Redis 服务器的内存非常容易成为存储瓶颈，需要进行数据分片。

拥有多个 Redis 服务器后就会面临如何管理集群等问题，包括如何增加节点、故障恢复等操作。

Redis 中的复制、哨兵（sentinel）和集群（cluster）的使用和原理。

#### 8.1 复制

避免单点服务器硬盘故障，导致的数据丢失，通常的做法是将数据库复制多个副本以部署在不同的服务器上，这样即使有一台服务器出现故障，其他服务器依然可以继续提供服务。

Redis 提供了复制（replication）功能，可以实现当一台数据库中的数据更新后，自动将更新的数据同步到其他数据库上。

**配置**

复制概念中，数据库分为两类，一类是主数据库（master），另一类是从数据库（slave）：

* 主数据库可以进行肚子饿操作，当写操作导致数据变化时会自动将数据同步给从数据库。

* 从数据库一般是只读的，并接受主数据库同步过来的数据，同主数据库是多对一的关系。

Redis 中使用复制，只需要在数据库的配置文件中加入 ``salveof 主数据库地址 主数据库端口`` 即可，主数据库无需进行任何配置。

通过配置 ``slave-read-only`` 为 no 可以使从数据库可写，但是更改不会同步给任何其他的数据库，并且一旦主数据库更新了对应数据，从数据库的改动会被覆盖掉，因此常设置为只读而不可写。

多台从数据库就在多个配置文件加上 slaveof 参数，也可以在运行时使用 SLAVEOF 命令，``SLAVEOF 127.0.0.1 6379``，可以改变从数据库的主数据库。

使用 SLAVEOF NO ONE 翻身农奴做主人。

**原理**

了解 Redis 复制的原理对日后运维有很大的帮助，包括如何规划节点、如何处理节点故障等。

具体过程：

1. 复制初始化：
   * 当一个从数据库启动后，会向主数据库发送 SYNC 命令；
   * 同时主数据库接收到 SYNC 命令后会开始在后台保存快照（即 RDB 持久化过程），并将保存快照期间接收到的命令缓存起来；
   * 快照完成后，Redis 会将快照文件和所有缓存的命令发给从数据库；
   * 从数据库收到后，会载入快照文件并执行收到的缓存的命令。
2. 复制初始化结束后，主数据库每当收到写命令时就会将命令同步给从数据库，保证两者数据的一致。
3. 当主从数据库之间的连接断开又重连后：
   * Redis 2.6 版本之前都会重新复制初始化，且数据全部重新传输，效率较低。
   * Redis 2.8 版本之后，改进断线重连能够支持有条件的增量数据传输，将断线期间执行的命令传送给从数据库即可。

协议角度：

Redis 服务使用 TCP 协议通信，可以使用 telnet 工具伪装成一个从数据库来与主数据库通信。

具体的过程可以根据书上来试试。

* ``telnet 127.0.0.1 6379`` 后会建立 TCP 连接，发送 PING 返回 PONG 即连接成功；
* 发送 ```REPLCONF listening-port 6381`` 表明自己的端口号。
* 发送 ``SYNC`` 命令开始同步，首先会发送回快照文件和缓存命令，从数据库收到后就将内容写入硬盘的临时文件，完成后会用临时文件替换掉原有的 RDB 快照文件；
* 同步过程中从数据库不会阻塞，可以继续处理客户端发来的命令，默认情况下会用同步前的数据对命令响应；
* 复制初始化结束后，数据变化的命令都会异步地传送，而且从数据库会不断的 PING？
* 复制同步阶段会一直到主从关系结束才终止。

快照无论是否开启 RDB 都会进行。

乐观复制 Redis 采用了乐观复制（optimistic replication）的复制策略，容忍一定时间内主从数据库内容不同，但最终会同步。

保证了启用复制后主数据库的性能不会受到影响，但另一方面也会产生一个主从数据库数据不一致的时间窗口。

Redis 提供了两个配置选项，限制只有当数据至少同步指定数量的从数据库时，主数据库才是可写的。

``min-slaves-to-write 3``，2意味着只有 3 及以上的从数据库链接到主数据库时，主数据库才是可写的，否则会返回错误。

``min-slaves-max-lag 10``，意味着允许数据库从数据库最长失去连接的时间，若从数据库最后与主数据库联系（即发送 REPLCONF ACK 命令）的时间小于这个值，则认为从数据库还在保持与主数据库的连接。

特性默认是关闭的，在分布式系统中，打开并合理配置该选项后可以降低主从架构中因为网络分区导致的数据不一致的问题。

**图结构**

从数据库不但可以接收主数据库的同步数据，也可以同时作为主数据库存在，形成类似图的结构。

数据库数据更改，只会影响到自己的子孙数据库。

**读写分离与一致性**

通过复制可以实现读写分离，以提高服务器的负载能力。

常见的场景中（如电子商务网站），读的频率大于写，当单机的 Redis 无法应付大量的读请求时（尤其是较耗资源的请求，如 SORT 命令等）。

可以通过复制功能建立多个从数据库节点，主数据库只进行写操作，而从数据库负责读操作。

单个数据库不能满足，就需要使用集群功能。

**从数据库持久化**

为提高性能，通过复制建立若干个从数据库，并在从数据库中启用持久化，同时在主数据库禁用持久化。

当从数据库崩溃重启后主数据库会自动将数据同步过来，无需担心数据丢失。

当主数据库崩溃时，情况就略显复杂。

手工通过从数据库恢复主数据库数据时，需要严格按照以下两步进行：

1. 在从数据库中使用 SLAVEOF NO ONE 命令将从数据库提升成主数据库继续服务；
2. 启动之前崩溃的主数据库，使用 SLAVEOF 命令将其设置成从数据库，将数据同步过来。

注意，开启复制且主数据库关闭持久化功能时，不要令主数据库崩溃自动重启，否则从数据库也会炸裂。

手工维护从数据库或主数据库重启以及数据恢复都相对麻烦，使用自动化方案哨兵可以实现这一过程。

**无硬盘复制**

使用 RDB 快照复制的缺点：

1. 主数据库禁用 RDB 快照时，如果执行了复制初始化操作，Redis 已然生成 RDB 快照，下次启动主数据库就会根据此 RDB 恢复数据，造成数据的缺失。
2. 若硬盘性能很慢，复制初始化在硬盘中创建 RDB 快照文件会性能较差。

Redis 2.8.18 版本后，引入了无硬盘复制选项，配置文件 ``repl-diskless-sync yes``。

开启后，主从数据库复制初始化会将快照直接通过网络发送给从数据库，而不需要存储到硬盘上。

**增量复制**

增量复制之前，从数据库断开重连后，需要发送 SYNC 命令完全复制所有数据，而不是复制增量数据。

增量复制基于如下 3 点实现：

1. 从数据库会存储主数据库的运行 ID（若主数据库掉线重连 ID 会改变）；
2. 复制同步阶段，主数据库传递的命令会同时存放到一个积压队列（backlog）中，并记录下当前积压队列中存放的命令的偏移量范围；
3. 从数据库接收到主数据库传来的命令，会记录下该命令的偏移量。

Redis 2.8 版本后，从数据库通过发送 PSYNC 命令来看是否可以进行增量复制：

1. 主数据库判断从数据库传来的运行 ID 是否和自己的相同，确保在之前两个数据库确实同步，否则会出错；
2. 判断从数据库最后同步成功的命令偏移量是否在积压队列中，如果在则可以进行增量复制，并将积压队列中相应的命令发送给从数据库。

不满足就会进行全部同步。

过程是全透明的，开发者只需要设置积压队列的大小。

配置文件 ``repl-backlog-size``，固定长度的循环队列，默认情况下 1 MB。

积压队列越大，明显的允许掉线时间越长，估算积压队列的大小只需要估计断线时间主数据库可能执行的命令大小。

另一配置 ``repl-backlog-ttl``，所有从数据库断开连接后，经过多久时间可以释放积压队列的内存空间，默认是 1 小时。

#### 8.2 哨兵

哨兵工具实现自动化系统监控和故障恢复功能。

**什么是哨兵**

哨兵的功能：

1. 监控主数据库和从数据库是否正常运行；
2. 主数据库出现故障时自动将从数据库转换为主数据库。

哨兵是一个独立进程：

<div style=" text-align: left;"><img src="H:\13_Spring\42_Linux\NeatReader-1595940530126.png" alt="NeatReader-1595940530126" style="zoom: 80%;" /></div>

在一主多从的 Redis 系统中，可以使用多个哨兵进行监控任务以保证系统稳健；哨兵除了监视主从数据库，还可以互相监控。

**马上上手**

配置哨兵，首先建立配置文件如 sentinel.conf，内容为 ``sentinel monitor mymaster 127.0.0.1 6379 1``。

mymaster 是自定义的监控的主数据库的名字，后面两个参数是地址和端口，最后的 1 是最低通过票数。

``$ redis-sentinel /path/to/sentinel.conf`` 启动 Sentinel 进程。

配置哨兵只需要监控主数据库，从数据库会自动发现。

将主数据库 SHUTDOWN 后，哨兵会输出：

```
12190:X 28 Jul 2020 21:12:55.303 # +sdown master mymaster 127.0.0.1 6379
12190:X 28 Jul 2020 21:12:55.303 # +odown master mymaster 127.0.0.1 6379 #quorum 1/1
```

+sdown 表示哨兵主干认为主数据库停止服务，+odown 表示哨兵客观认为主数据库停止服务。

后续输出中，+try-failover 表示哨兵开始进行故障恢复，+failover-end 表示哨兵完成故障恢复，期间包括零头烧饼选举、备选从数据库的选择等。

```
12190:X 28 Jul 2020 21:15:55.495 # +switch-master mymaster 127.0.0.1 6379 127.0.0.1 6381
12190:X 28 Jul 2020 21:15:55.495 * +slave slave 127.0.0.1:6380 127.0.0.1 6380 @ mymaster 127.0.0.1 6381
12190:X 28 Jul 2020 21:15:55.495 * +slave slave 127.0.0.1:6379 127.0.0.1 6379 @ mymaster 127.0.0.1 6381
```

重点关注以上三条，其中表示 6381 成为主数据库，而 6380 和 6379 成为从数据库。

6379 虽然停止服务，但哨兵并没有去除实例，因为可能恢复服务再加入到主从数据库中。

```
12190:X 28 Jul 2020 21:19:56.193 # -sdown slave 127.0.0.1:6379 127.0.0.1 6379 @ mymaster 127.0.0.1 6381
12190:X 28 Jul 2020 21:20:06.186 * +convert-to-slave slave 127.0.0.1:6379 127.0.0.1 6379 @ mymaster 127.0.0.1 6381
```

重启 6379 后，出现 -sdown 表示已经恢复，而 +convert-to-slave 表示设置为从数据库。

**实现原理**

哨兵进程启动会读取配置文件的内容，找出需要监控的主数据库：

```
sentinel monitor master-name ip redis-port quorum
```

master-name 是大小写字母，数字和 “.-_” 组成的转速忽数据库名字；考虑到故障恢复后地址和端口会变化，则可以通过名字获取变化后的地址和端口号。

ip 表示当前系统中主数据库的地址，redis-port 表示端口号。

quorum 表示执行故障恢复操作前至少需要几个哨兵节点同意。

一个哨兵节点可以同时监控多个 Redis 主从系统，只要在配置中增加新行即可。

多个哨兵节点也可以同时监控同一个 Redis 主从系统，形成网状结构。

配置文件还可以定义其他监控相关的参数，如``sentinel down-after-milliseconds mymaster 60000``。

哨兵启动后，会与要监控的主数据库建立两条连接，建立方式也是 TCP 连接：

1. 一条连接用来订阅盖住数据库的 \_\_sentinel\_\_:hello  频道获取其他哨兵节点信息；
2. 另一条定期向主数据库发送 INFO 等命令，因为订阅的连接无法发送命令。

建立连接后，哨兵会定时执行下面的操作：

1. 每 10 秒哨兵向主数据库和从数据库发送 INFO 命令；
2. 每 2 秒哨兵向主数据库和从数据库的 \_\_sentinel\_\_:hello 频道发送自己的信息；
3. 每 1 秒哨兵向主数据库、从数据库和其他哨兵节点发送 PING 命令。

了解了以上 3 个操作意义就能够了解哨兵工作原理的一半内容了。

INFO 命令：

* 获得当前数据库的相关信息（运行 ID、复制信息等），实现新结点的自动发现。
* 可以通过 INFO 命令获得从数据库的信息，并解析结果同从数据库建立连接。
* 重复发送 INFO 命令以进行信息更新，如从数据库增加、主数据库故障和恢复等。

\_\_sentinel__:hello 频道：

* 在频道上发送信息来与同样监控该数据库的哨兵分享自己的信息。
* 消息内容为 <哨兵的地址>，<哨兵的端口>，<哨兵的运行ID>，<哨兵的配置版本>、<主数据库的名字>，<主数据库的地址>，<主数据库的端口>，<主数据库的配置版本>。
* 其他哨兵收到消息，会判断是否是新哨兵并建立连接，哨兵间的连接只创建一条来发送 PING 命令。
* 同时哨兵会判断信息中主数据库的配置版本，若该版本比当前记录的主数据库高，则更新主数据库的数据。

PING 命令：

* 定时监控数据库和节点有没有停止服务。
* 时间间隔同 ``down-after-millisecond`` 配置有关，小于 1 秒按原值，大于 1 秒按 1 秒。
* 超过指定时间没有回复则认为主观下线。
* 若为主数据库，哨兵就发送 ``SENTINEL is-master-down-by-addr`` 命令询问其他哨兵以了解主数据库是否下线；达到指定数量（quorum），哨兵会认为其客观下线（objectively down），并选举领头哨兵节点对主从系统发起故障恢复。

选举领头哨兵的步骤，采用了 Raft 算法：

1. 发现主数据库客观下线的哨兵节点（A）向每个哨兵节点发送命令（不是说只能 PING 吗），要求选自己成为领头哨兵。
2. 如果目标节点没有选过其他人，则会同意将 A 设置成领头哨兵。
3. 如果 A 发现超过半数且超过 quorum 参数值的哨兵节点同意，就成为领头哨兵。
4. 当有多个哨兵节点同时参选，会出现没有节点当选的可能；此时各个参选节点等待一个随机事件重新发起请求，进行下一轮选举，直到选举成功。

具体过程参考 Raft 算法的过程 http://raftconsensus.github.io/。

领头哨兵会对主数据库进行故障恢复：

1. 首先，在从数据库中挑选一个充当新的主数据库：
   1. 所有在线的从数据库中选择优先级最高的，通过 slave-priority 选项设置；
   2. 多个并列最高优先级，则复制的命令偏移量越大越优先（数据越完整）；
   3. 以上条件都一样，选择运行 ID 较小的从数据库。
2. 领头哨兵向从数据库发送 SLAVEOF  NO ONE 命令升级，向其他从数据库发送 SLAVEOF 命令改变主数据库。
3. 更新内部记录，将旧的主数据库更新为新的主数据库的从数据库。

**哨兵的部署**

如果主从系统中配置的哨兵较少，对整个系统的判断可靠性就会降低。

相对稳妥的哨兵部署方案是使得哨兵视角尽可能地以每个结点视角一致；即：

1. 为每个节点（无论是主数据库还是从数据库）部署一个哨兵；
2. 使每个哨兵与其对应的节点的网络环境相同或相近。

举例：当网络分区后，若哨兵认为某个分区是主要分区，即以为从每个结点观察，该分区均为主分区。

设置 quorum 值为 N/2+1，使得只有大部分哨兵节点同意才会进行故障恢复。

不过哨兵数量过多，可能会产生较多连接，见此 issue：https://github.com/antirez/redis/issues/2257；Redis 节点敷在较高，也会一定程度上影响其对哨兵的回复以及与其同机的哨兵与其他节点的通信。

配置哨兵根据是集生产环境情况选择。

#### 8.3 集群

前面所述的 Redis 集群内所有数据库有存储集群中的所有数据，导致总数据存储量受限于可用存储内存最小的数据库节点，形成木桶效应。

对于以内存存储的 Redis 来说，更难受。

对 Redis 进行水平扩容，在旧版中使用客户端分片，即启动多个 Redis 数据库节点，有客户端决定每个键交给哪个节点存储，下次客户端直接到该结点读取。

整个数据分布存储在 N 个数据库节点中，每个节点只存放 1/N 的数据。

如果是需要扩容的场景，客户端分片后就需要手工迁移，迁移过程中还需要将集群暂时下线，总之比较复杂。

考虑到 Redis 轻量，采用预分片技术（presharding）来在一定程度上避免此问题。

具体来说在节点部署初期，就提前考虑日后的存储规模，建立足够多的实例（如 128 个结点）。

初期存储少，但实例轻量，数据外占据的空间较小；待数据量增大后，将某些实例迁移到其他服务器上即可。

无论如何，客户端分片总是有很多缺点，如维护成本高，增加、移除节点较繁琐等。

Redis 3.0 支持集群（Cluster）。

集群的特点在于拥有和单机实例同样的性能，同时在网络分区后能够提供一定的可访问性以及对主数据库故障恢复的支持。

集群也支持几乎所有的单机实例支持的命令；对于涉及多键的命令（如 MGET0，若每个键都位于同一个节点，则可以正常支持，否则就报错。

集群还有一个限制是只能使用默认的 0 号数据库，如果执行 SELECT 切换数据库则会提示错误。

哨兵和集群是两个独立的功能，从特性来看哨兵可以视为集群的子集，需要水平扩展就选择集群。

**配置集群**

将各数据库节点的 cluster-enabled 配置选项打开即可，一个集群至少需要 3 个主数据库才能正常运行。

各个数据库的节点都需要有自己的配置文件，并有不同的工作目录。

集群会将当前节点记录的集群状态持久化地存储在指定文件中，默认为当前工作目录下的 nodes.conf 文件。

nodes.conf 文件每个结点都有一个，因此工作目录不同或 cluster-config-file 选项修改持久化文件的名称。

节点启动会输出：

```
No cluster configuration found, I'm c21d9182eec935720f1622…
```

末尾是该结点的运行 ID，在集群中的唯一标识，同一个运行 ID 地址和端口可能不同。

redis-cli 连接任一结点 INFO cluster 命令判断集群是否可用。

要将结点从完全独立加入到同一集群，使用 redis-trib.rb 工具（使用 Ruby 编写），执行：

```
$ /path/to/redis-trib.rb create --replicas 1 127.0.0.1:6380 127.0.0.1:6381 127.0.0.1:6382 127.0.0.1:6383 127.0.0.1:6384 127.0.0.1:6385
```

--replicas 1 表示每个主数据库有几个从数据库。

返回的内容包括集群的具体分配方案，具体创建过程：

1. redis-trib.rb 以客户端的形式连接所有节点，发送 PING 确定节点正常服务；若有无法连接，则创建失败；
2. 同时发送 INFO 命令获取运行 ID 以及是否开启集群功能；
3. 准备就绪后向各节点发送 CLUSTER MEET 命令，格式为 CLUSTER MEET ip port，告诉当前节点指定 ip 和 port 上在运行的节点也是集群的一部分；
4. 之后 redis-trib.rb 分配主从数据库节点，分配原则是尽量保证每个主数据库运行在不同 IP 地址上，同时每个从数据库和主数据库均不运行在同一 IP 地址上，以保证系统的容灾能力。
5. 分配完成后，为每个主数据库分配插槽，分配插槽的过程其实就是分配哪些键归哪些节点负责；
6. 之后对每个要成为从数据库的节点发送 CLUSTER REPLICATE 主数据库运行 ID 来讲当前节点转换成从数据库并赋值指定运行 ID 的节点。

不过 redis-trib.rb 就是辅助工具，功能通过手动也可以建立的。

**节点的增加**

加入新的节点，使用 CLUSTER MEET 命令。

向新结点发送如下命令 ``CLUSTER MEET ip port`` ，ip 和 port 是集群中任意一个节点的地址和端口号。

新结点 A 接收到来自客户端的命令，会与该地址和端口号的节点 B 进行握手，使 B 将 A 认作当前集群中的意愿。

B 与 A 握手成功后，B 会使用 Gossip 协议将节点 A 的信息通知给集群中的每一个节点。

**插槽的分配**

新加入的节点，要么使用 CLUSTER REPLICATE 命令复制每个主数据库以从数据库的形式运行，要么向集群中申请分配插槽（slot）来以主数据库的形式运行。

集群中，所有的键都会分配给 16384 个插槽，每个主数据库会负责处理其中的一部分。

Redis 将每个键的键名有效部分使用 CRC16 算法计算出散列值，取对 16384 的余数，使得每个键都有插槽，分配的指定一个结点中处理。

插槽分配分以下两种情况：

1. 插槽之前没有分配过，现在想分配给指定节点；
2. 插槽之前被分配过，现在想移动到指定节点。

情况 1 使用 CLUSTER ADD SLOTS 命令来实现，``CLUSTER ADD SLOTS slot1 [slot2] ... [slotN]。

通过 CLUSTER SLOTS 来查看插槽分配情况。

情况 2 可以使用 redis-trib.rb 来进行简便的处理：

1. 执行 ``$ /path/to/redis-trib.rb reshard 127.0.0.1:6380``，reshard 表示要重新分片，redis-trib.rb 根据任一结点地址和端口自动获取集群信息；
2. redis-trib.rb 询问具体如何进行重新分片，首先询问要迁移多少个插槽；
3. 之后询问迁移到哪个节点，用运行 ID 来标识；
4. 询问从哪个结点移出插槽。

手工重新分片，``CLUSTER SETSLOT 插槽号 NODE 新结点的运行ID`` 即可。

如此手工迁移插槽前提是插槽中没有任何键，键不会随着插槽进行迁移，会导致数据“丢失”，为此还要手工迁移键。

获取某个插槽存在的键：``CLUSTER GETKEYSSINSLOT 插槽号要返回的键的数量``。

之后对每个键，都是用 MIGRATE 命令将其迁移到目标节点：

```
MIGRATE 目标价店地址 目标节点端口 键名 数据库号码 超时时间 [COPY] [REPLACE]
```

迁移时间会比较长，如何不下线进行迁移？

用 redis-trib.rb 工具，Redis 提供了两个命令能够在不下线的情况下迁移数据：

```
CLUSTER SETSLOT 插槽号 MIGRATING 新结点的运行ID
CLUSTER SETSLOT 插槽号 IMPORTING 原结点的运行ID
```

进行迁移时，假设要把 0 号插槽从 A 迁移到 B，此时 redis-trib.rb 会依次执行如下操作：

1. 在 B 执行 CLUSTER SETSLOT 0 IMPORTING A
2. 在 A 执行 CLUSTER SETSLOT 0 MIGRATING B
3. 执行 CLUSTER GETKEYSINSLOT 0 获取 0 号插槽的键列表
4. 对第 3 步获取的每个键执行 MIGRATE 命令，将其从 A 迁移到 B
5. 执行 CLUSTER SETSLOT 0 NODE B 来完成迁移。

客户端请求过程：

1. 执行完前两步，当客户端向 A 请求 0 中的键，如果键存在（尚未迁移）则正常处理；
2. 如果不存在则返回一个 ASK 跳转请求，告知键在 B 中；
3. 客户端接收到 ASK 跳转请求后，向 B 发送 ASKING 命令，在重新发送之前的命令；
4. 当客户端向 B 请求 0 中的键时，若前面执行了 ASKING 命令，则返回键值内容，否则返回 MOVED 跳转请求指向 A。

**获取与插槽对应的节点**

当客户端向集群中任一结点发送命令后，该节点会判断键是否在结点中，若在则返回值，若不在则返回 MOVE 重定向请求，告诉客户端该键由哪一个节点负责，然后客户端向目标节点再发请求以获得结果。

有的语言 Redis 库支持集群可以直接用透明的，如果不支持那就需要客户端编码处理了。

若键 foo 由 6382 负责，在 6380 执行：

```
redis 6380> SET foo bar
(error) MOVED 12182 127.0.0.1:6382
```

返回的内容较容易理解，只要解析它再向目标节点发送命令，即可手工实现。

Redis 命令行客户端提供了集群模式来支持自动重定向，使用 -c 参数启动，可以自动发送重定向命令。

当发现新的重定向请求时，客户端应该在重新向正确节点发送命令的同时，缓存插槽的路由信息，即记录下当前插槽是由哪个节点负责的，可以提高性能。

**故障恢复**

集群中，每个结点都会定期向其他节点发送 PING 命令，并通过有没有收到回复来判断目标节点是否下线。

具体的，每 1 秒回随机选择 5 个结点，选择其中最久没有响应的节点发送 PING。

一定时间没有回复，就认为疑似下限（PFALL），同哨兵主观下线类似。

一定数量节点认为某节点疑似下线：

1. 一旦 A 认为 B 疑似下线，就会在集群中传播消息，所有结点收到消息都会记录下信息；
2. 当集群中某一节点 C 收集到半数以上的节点认为 B 疑似下线时，就会标记 B 为下线（FAIL），并传播消息使在集群中下线。

一个主数据库下线，就会使部分插槽无法写入；若有从数据库，集群就进行故障恢复操作来将其中一个转变成主数据库。

选择从数据库的过程也是基于 Raft 算法：

1. 发现其复制的主数据库下线的从数据库（下面称作A）向每个集群中的节点发送请求，要求对方选自己成为主数据库。
2. 如果收到请求的节点没有选过其他人，则会同意将A设置成主数据库。
3. 如果A发现有超过集群中节点总数一半的节点同意选自己成为主数据库，则A则成功成为主数据库。
4. 当有多个从数据库节点同时参选主数据库，则会出现没有任何节点当选的可能。此时每个参选节点将等待一个随机时间重新发起参选请求，进行下一轮选举，直到选举成功。

当某个从数据库当选为主数据库后，会通过命令 SLAVEOF ON ONE将自己转换成主数据库，并将旧的主数据库的插槽转换给自己负责。

如果一个至少负责一个插槽的主数据库下线且没有相应的从数据库可以进行故障恢复，则整个集群默认会进入下线状态无法继续工作。

如果想在这种情况下使集群仍能正常工作，可以修改配置cluster-require-full-coverage为no（默认为yes）：cluster-require-full-coverage no



### Chapt 9 管理

Redis 的管理知识，包括安全和协议等内容。

#### 9.1 安全

Redis 以简洁为美，因此安全层面也没做太多工作。

**可信的环境**

运行在可信的环境中是保证 Redis 安全的最重要方法。

配置文件中，bind 参数为 127.0.0.1 可以使得只允许本机应用连接 Redis。

bind 只能绑定一个地址，更自由地设置访问规则需要通过防火墙来完成。

**数据库密码**

配置文件中的 requirepass 参数为 Redis 设置一个密码，例如：

```
requirepass TAFK(@~!ji^XALQ(sYh5xIwTn5D$s7JF
```

客户端每次连接 Redis 时都需要发送密码，使用 AUTH 命令：

```
AUTH TAFK(@~!ji^XALQ(sYh5xIwTn5D$s7JF
```

Redis 性能较高，且输错密码后不会主动延迟，因此暴力破解 1 秒能够尝试是几万个，在设置时一定要选择复杂的密码。

配置复制时，若主数据库设置了密码，需要在从数据库的配置文件中通过 masterauth 参数设置主数据库的密码，自动使用 AUTH 连接。

**命名命令**

支持在配置文件中将命令重命名，以保证只有自己能够使用，比如：

```
rename-command FLUSHALL oyfekmjvmwxq5a9c8usofuo369x0it2k
```

或是直接禁用：

```
rename-command FLUSHALL ""
```

不过，这里的安全都建立在配置文件是安全的基础上。

#### 9.2 通信协议

Redis 通信协议，是 Redis 客户端与 Redis 之间交流的语言，通信协议规定了命令和返回值的格式。

了解通信协议可以理解 AOF 文件的格式、主从数据库复制时大宋的内容等，还可以开发自己的 Redis 客户端。

两种通信协议：

* 二进制安全的统一请求协议（unified request protocol）
* 在 telnet 程序中输入的简单协议

两者的命令格式有区别，命令返回值的格式是一样的。

**简单协议**

适合在 telnet 程序中和 Redis 通信。

简单协议命令格式就是将命令和各个参数使用空格分隔开，如 EXISTS foo、SET foo bar 等。

Redis 真正的返回格式：

1. 错误回复

   以 - 开头，并在后面跟上错误信息，最后以 \r\n 结尾

2. 状态回复

   以 + 开头，并在后面跟上状态信息，最后以 \r\n 结尾

3. 整数回复

   以 : 开头，并在后面跟上数字，最后以 \r\n 结尾

4. 字符串回复

   以 $ 开头，并在后面跟上字符串的长度，以 \r\n 分隔，接着是字符串的内容和 \r\n

   若是空串，则返回 $-1

5. 多行字符串回复

   以 * 开头，并在后面跟上字符串回复的组数，并以 \r\n 分隔，然后是各个字符串回复。

**统一请求协议**

命令格式和多行字符串回复的格式很类似，如 SET foo bar：

```
*3\r\n$3\r\nSET\r\n$3\r\nfoo\r\n$3\r\nbar\r\n
```

统一请求协议的返回值格式和简单协议一样。

#### 9.3 管理工具

**redis-cli**

Redis 自带的命令行客户端。

可以执行大部分 Redis 命令，下面是管理 Redis 非常有用的命令：

1. 耗时日志命令：

   当一条命令执行时间超过限制，Redis 会将命令执行时间等信息加入耗时命令日志（slow log）。

   通过配置文件 slowlog-log-lower-than 参数设置限制，单位微秒，设置为负数会关闭耗时命令。

   配置 slowlog-max-len 参数限制记录条数。

   SLOWLOG GET 命令获得当前的耗时命令日志。

   日志有 4 个部分组成：

   1. 日志的唯一 ID
   2. 执行的 Unix 时间
   3. 耗时时间
   4. 命令及参数

2. 命令监控：

   MONITOR 命令来监控执行的所有命令。

   Redis 执行的任何命令都会在 redis-cli 中打印出来，比如在另一个 redis-cli 中执行命令。

   MONITOR 影响性能，一个客户端使用会降低一半的负载能力。

   只适用调试和纠错。

   redis-faina 是 Instagram 团队开发的分析程序，很牛逼。

**phpRedisAdmin**

由 PHP 开发的网页端管理工具。

支持以树形结构查看键列表、编辑键值、导入/导出数据库数据等。

Redis 使用单线程处理命令，对生产环境下拥有大数据量的数据库来说不适宜使用。

**Rdbtools**

Python 开发的 Redis 快照文件解析器。

根据快照文件导出 JSON 数据文件、分析 Redis 中键的空间占用情况等。